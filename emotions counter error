from google.colab import drive
drive.mount('/content/drive')

import nltk
#from nltk.corpus import wordnet
from nltk.corpus import stopwords
from nltk import word_tokenize
nltk.download('punkt')

text=open('/content/drive/MyDrive/Classroom Studies/NLP Files/hello.txt', encoding="UTF-8").read()
text

emotions=open('/content/drive/MyDrive/Classroom Studies/NLP Files/emotion.txt', encoding="UTF-8").read()

text=text.replace('\n','').replace(",","").replace("'","").replace("’","").replace('?','').replace("”","").replace("“","").replace(":","")
text=text.replace(".","").replace("?","").replace("-","").lower()
text

nltk.download('stopwords')
words=word_tokenize(text)
clean_words=[]
for w in words:
 if w not in stopwords.words('english'):
  clean_words.append(w)
clean_words

emotions=[]
with open('/content/drive/MyDrive/Classroom Studies/NLP Files/emotion.txt','r') as file:
  for i in file:
    j=i.replace("\n","").strip().replace("'","").replace(",","").replace("-","")
    word,emotion=j.split(":")
    #print(emotion)
    #print(word)
    if word in clean_words:
      emotions.append(word)
      
from typing import Counter
w=Counter(emotions)
from nltk.sentiment import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt
nltk.download('vader_lexicon')

def getSentiments(wordsss):
  return SentimentIntensityAnalyzer().polarity_scores(wordsss)

score=getSentiments(text)
fig,ax=plt.subplots()
ax.bar(score.keys(),score.values())
plt.show()

fig,ax=plt.subplots()
fig.autofmt_xdate()
ax.bar(w.keys(),w.values())
plt.show()
